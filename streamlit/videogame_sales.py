import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.style as style

style.use('ggplot')



st.write("# Video Game Sales")

st.write("""

## Description

This dataset contains a list of video games with sales greater than 100,000 copies. It was generated by a scrape of vgchartz.com.

## Fields include

- Name - The games name
- Platform - Platform of the games release (i.e. PC,PS4, etc.)
- Year - Year of the game's release
- Genre - Genre of the game
- Publisher - Publisher of the game
- NA_Sales - Sales in North America (in millions)
- EU_Sales - Sales in Europe (in millions)
- JP_Sales - Sales in Japan (in millions)
- Other_Sales - Sales in the rest of the world (in millions)
- Global_Sales - Total worldwide sales.

The script to scrape the data is available at https://github.com/GregorUT/vgchartzScrape.
It is based on BeautifulSoup using Python.
There are 16,598 records. 2 records were dropped due to incomplete information.

# Objective

It is possible to divide data analysis into two fields: Hypothesis Generation and Hypothesis Confirmation (Also called confirmatory analysis).
In this project I will deal only with exploratory analysis, where the objective is to understand how the data is distributed and generate insight for future decision-making, this analysis aims to explore as much as possible the data in a simple, intuitive and informative way. The data used in this project contains information only from 1980 to 2016. Below is a sketch of all the stages made in these notebooks, following a logical and intuitive sequence to facilitate the understanding of the data.
""")

st.write("""
OutlineÂ¶

**1. Libraries & Data loading**
A. Used Libraries
B. Database Loading
C. Summary of data

**2. Descriptive Analysis**
A. Frequency Distribution
B. Central Trend Measures
C. Separating Measures
D. Dispersion Measures

**3. Exploratory Analysis**
A. Analysis of the world's best-selling games
B. Number of Sales per platform
C. Game Sales by Genre
D. Number of sales per publisher
E. Global Sales Number per Year
""")

st.write(
"""
# 1. Libraries & Data loading

A. Used Libraries
```
# Visualization
import matplotlib.pyplot as plt
import seaborn as sns

# Data Manipulation
import pandas as pd
import numpy as np

# Hypothesis Testing
from scipy import stats
```
"""
)

st.write(
"""
B. Database Loading
```
vgsales_df = pd.read_csv("/home/israel/my_repos/DataScience/streamlit/vgsales.csv")
```
"""
)

vgsales_df = pd.read_csv("/home/israel/my_repos/DataScience/streamlit/vgsales.csv")

# Clean Data
# Remove column 'Rank'
vgsales_df.drop('Rank', axis=1, inplace=True)

st.dataframe(vgsales_df[vgsales_df['Year'] >= 2017])

# Remove rows when 'Year' is equal or greather than 2017
vgsales_df.drop(vgsales_df[vgsales_df['Year'] >= 2017].index, inplace=True)

st.write(

"""
# 2. Descriptive Analysis
"""
)

not_null_year_df = vgsales_df[vgsales_df['Year'].notnull()].copy()

group_by_df = not_null_year_df.groupby('Year').sum().reset_index().copy()
group_by_df['Year'] = group_by_df['Year'].astype(str)
group_by_df['Porcent'] = (group_by_df['Global_Sales'] / group_by_df['Global_Sales'].sum()) * 100

years_df = group_by_df.copy()
years_df['Year'] = years_df['Year'].str.replace(".0", "", regex=False).copy()

most_years_df = years_df.nlargest(10, 'Porcent').groupby('Year').sum().reset_index().copy()
least_years_df = years_df.nsmallest(10, 'Porcent').groupby('Year').sum().reset_index().copy()

least_years_df['Porcent'] = least_years_df['Porcent'].round(2)
most_years_df['Porcent'] = most_years_df['Porcent'].round(2)

year_bar_colors = ['#ff9999','#66b3ff','#99ff99','#ffcc99','#c2c2f0']

plt.figure(figsize=(8, 5))
plt.bar(most_years_df['Year'], most_years_df['Porcent'], color=year_bar_colors)
plt.xlabel('Year')
plt.ylabel('Porcent')
plt.title('The 10 most frequent years in the database')

for i in range(len(most_years_df['Year'])):
    plt.text(i, most_years_df['Porcent'][i], f"{most_years_df['Porcent'][i]:.2f}%", ha='center')

st.pyplot(plt)

plt.figure(figsize=(8, 5))
plt.bar(least_years_df['Year'], least_years_df['Porcent'], color=year_bar_colors)
plt.xlabel('Year')
plt.ylabel('Porcent')
plt.title('The 10 least years in the database')

for i in range(len(least_years_df['Year'])):
    plt.text(i, least_years_df['Porcent'][i], f"{least_years_df['Porcent'][i]:.2f}%", ha='center')

st.pyplot(plt)

st.markdown("# Sales by Region")

# Pizza Graphic
regions = {
    'NA_Sales': "North\nAmerica\nSales",
    'EU_Sales': "Europe\nSales",
    'JP_Sales': "Japan\nSales",
    'Other_Sales': "Other\nSales"
}
sales = vgsales_df[regions.keys()].sum()
fig, ax = plt.subplots()
plt.pie(sales, labels=regions.values(), autopct='%1.1f%%', startangle=90, colors=['#ff9999','#66b3ff','#99ff99','#c2c2f0'])
ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.

st.pyplot(fig)
    
st.markdown("# Sales by Genre")

genre_df = vgsales_df.groupby('Genre').sum().reset_index().copy()
genre_df['Porcent'] = (genre_df['Global_Sales'] / genre_df['Global_Sales'].sum()) * 100
genre_df['Porcent'] = genre_df['Porcent'].round(2)

genre_df = genre_df.nlargest(10, 'Porcent').groupby('Genre').sum().reset_index().copy()

genre_df_bar_colors = ['#ff9999','#66b3ff','#99ff99','#c2c2f0']

plt.figure(figsize=(10, 4))
plt.bar(genre_df['Genre'], genre_df['Porcent'], color=genre_df_bar_colors)

for i in range(len(genre_df['Genre'])):
    plt.text(i, genre_df['Porcent'][i], f"{genre_df['Porcent'][i]:.2f}%", ha='center')

st.pyplot(plt)

